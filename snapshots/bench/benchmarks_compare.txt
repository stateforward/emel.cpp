# ref=94b0200a01a753eff5897dab9311f51a7bc1c62f
# toolchain=/opt/homebrew/bin/zig
batch/splitter_equal emel.cpp 1590.067 ns/op, llama.cpp 6551.321 ns/op, ratio=0.243x
batch/splitter_seq emel.cpp 1494.233 ns/op, llama.cpp 2769.658 ns/op, ratio=0.540x
batch/splitter_simple emel.cpp 764.492 ns/op, llama.cpp 2407.667 ns/op, ratio=0.318x
buffer/allocator_alloc_graph emel.cpp 17.333 ns/op, llama.cpp 56.792 ns/op, ratio=0.305x
buffer/allocator_full emel.cpp 39.583 ns/op, llama.cpp 263.475 ns/op, ratio=0.150x
buffer/allocator_reserve_n emel.cpp 20.758 ns/op, llama.cpp 450.979 ns/op, ratio=0.046x
jinja/parser_long emel.cpp 32224.275 ns/op, llama.cpp 50599.421 ns/op, ratio=0.637x
jinja/parser_short emel.cpp 404.867 ns/op, llama.cpp 506.729 ns/op, ratio=0.799x
jinja/renderer_long emel.cpp 94664.079 ns/op, llama.cpp 232153.237 ns/op, ratio=0.408x
jinja/renderer_short emel.cpp 1574.596 ns/op, llama.cpp 3978.121 ns/op, ratio=0.396x
memory/coordinator_recurrent_full emel.cpp 3873.150 ns/op, llama.cpp 5626.817 ns/op, ratio=0.688x
tokenizer/preprocessor_bpe_long emel.cpp 16275.712 ns/op, llama.cpp 16453.733 ns/op, ratio=0.989x
tokenizer/preprocessor_bpe_short emel.cpp 509.725 ns/op, llama.cpp 692.804 ns/op, ratio=0.736x
tokenizer/preprocessor_plamo2_long emel.cpp 3142.508 ns/op, llama.cpp 4691.025 ns/op, ratio=0.670x
tokenizer/preprocessor_plamo2_short emel.cpp 2429.562 ns/op, llama.cpp 3608.113 ns/op, ratio=0.673x
tokenizer/preprocessor_rwkv_long emel.cpp 3149.004 ns/op, llama.cpp 4657.842 ns/op, ratio=0.676x
tokenizer/preprocessor_rwkv_short emel.cpp 2500.412 ns/op, llama.cpp 3560.512 ns/op, ratio=0.702x
tokenizer/preprocessor_spm_long emel.cpp 3164.762 ns/op, llama.cpp 4422.837 ns/op, ratio=0.716x
tokenizer/preprocessor_spm_short emel.cpp 2489.713 ns/op, llama.cpp 3470.771 ns/op, ratio=0.717x
tokenizer/preprocessor_ugm_long emel.cpp 3222.725 ns/op, llama.cpp 4466.550 ns/op, ratio=0.722x
tokenizer/preprocessor_ugm_short emel.cpp 2468.867 ns/op, llama.cpp 3528.483 ns/op, ratio=0.700x
tokenizer/preprocessor_wpm_long emel.cpp 3217.846 ns/op, llama.cpp 4422.783 ns/op, ratio=0.728x
tokenizer/preprocessor_wpm_short emel.cpp 2435.762 ns/op, llama.cpp 3464.592 ns/op, ratio=0.703x
